# Identify Outliars
# DT = loaded dataframe
# cut.well = threshold for well outliaer,
# cut.point = threshold for point outliaer
# x = Variable: "LOCR" or "OCR" or "ECAR"
dm_r <- idfy_outliar(DT = dm, cut.well = 5, cut.point = 7, x = "LOCR" )  # could Print arguments
b <- compute_bioenergetics(dm_r)
# Print interval estimates
b$coef %>%
kable(digits = 3) %>%
kable_styling()
b <- compute_bioenergetics(dm_r)
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
b <- compute_bioenergetics(dm_r)
# Print interval estimates
b$coef %>%
kable(digits = 3) %>%
kable_styling()
# Print interval estimates
b$estim %>%
kable(digits = 3) %>%
kable_styling()
# Print interval estimates
b$estim %>%
kable(digits = 3) %>%
kable_styling(full_width = F)
b$err %>%
kable(digits = 3) %>%
kable_styling(full_width = F)
b <- compute_bioenergetics(dm_r)
# Print interval estimates
b$estim %>%
kable(digits = 3) %>%
kable_styling(full_width = F)
estim <- b$coef_melted
View(estim)
# Plot to show errors
ggplot(estim)+
geom_line(aes(Interval, Estimate, group = Sample))+
geom_errorbar(aes(ymin = Estimate - 2*SdEr, ymax = Estimate + 2*SdEr, x = Interval), width=.2, position=position_dodge(.9)) +
geom_text(aes(Interval, Estimate, label = paste(format(Estimate, digits=1, nsmall=1))),size = 2, vjust = -1)+
facet_wrap(.~ Sample)+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
write_csv(b$err, OUTPUT_PATH)
table <- merge(b$err, b$estim)
View(table)
table <- cbind(b$err, b$estim)
View(table)
table <- cbind(Estim = b$estim, Er = b$err)
write_csv(table, paste0(OUTPUT_PATH,"/Log_Estimates.csv"))
paste0(OUTPUT_PATH,"/Log_Estimates.csv")
View(dm_r)
bio_e <- b$bio_e
ggplot(bio)+
geom_boxplot(aes(variable,value))+
geom_point(aes(variable,value))
bio <- melt(bio_e)
ggplot(bio)+
geom_boxplot(aes(variable,value))+
geom_point(aes(variable,value))
ggplot(bio)+
geom_boxplot(aes(variable,value))+
geom_point(aes(variable,value))+
xlab("Bio-Energetics")+
ylab(" ")
ggplot(bio)+
geom_boxplot(aes(variable,value))+
geom_point(aes(variable,value, col = Sample))+
xlab("Bio-Energetics")+
ylab(" ")
ggplot(estim)+
geom_tile("Log Estimates of Intervals across samples")
ggplot(estim)+
geom_tile("Log Estimates of Intervals across samples")
ggplot(estim)+
geom_tile("Log Estimates of Intervals across samples")+
geom_line(aes(Interval, Estimate, group = Sample))+
geom_errorbar(aes(ymin = Estimate - 2*SdEr, ymax = Estimate + 2*SdEr, x = Interval), width=.2, position=position_dodge(.9))
# Plot to show errors
ggplot(estim)+
geom_tile("Log Estimates of Intervals across samples")+
geom_line(aes(Interval, Estimate, group = Sample))+
geom_errorbar(aes(ymin = Estimate - 2*SdEr, ymax = Estimate + 2*SdEr, x = Interval), width=.2, position=position_dodge(.9)) +
geom_text(aes(Interval, Estimate, label = paste(format(Estimate, digits=1, nsmall=1))),size = 2, vjust = -1)+
facet_wrap(.~ Sample)+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Plot to show errors
ggplot(estim, aes(Interval, Estimate))+
geom_tile("Log Estimates of Intervals across samples")+
geom_line(aes(Interval, Estimate, group = Sample))+
geom_errorbar(aes(ymin = Estimate - 2*SdEr, ymax = Estimate + 2*SdEr, x = Interval), width=.2, position=position_dodge(.9)) +
geom_text(aes(Interval, Estimate, label = paste(format(Estimate, digits=1, nsmall=1))),size = 2, vjust = -1)+
facet_wrap(.~ Sample)+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Plot to show errors
ggplot(estim)+
#geom_tile("Log Estimates of Intervals across samples")+
geom_line(aes(Interval, Estimate, group = Sample))+
geom_errorbar(aes(ymin = Estimate - 2*SdEr, ymax = Estimate + 2*SdEr, x = Interval), width=.2, position=position_dodge(.9)) +
geom_text(aes(Interval, Estimate, label = paste(format(Estimate, digits=1, nsmall=1))),size = 2, vjust = -1)+
facet_wrap(.~ Sample)+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(estim)+
geom_tile(aes("Log Estimates of Intervals across samples"))+
geom_line(aes(Interval, Estimate, group = Sample))+
geom_errorbar(aes(ymin = Estimate - 2*SdEr, ymax = Estimate + 2*SdEr, x = Interval), width=.2, position=position_dodge(.9))
ggplot(estim)+
geom_line(aes(Interval, Estimate, group = Sample))+
geom_errorbar(aes(ymin = Estimate - 2*SdEr, ymax = Estimate + 2*SdEr, x = Interval), width=.2, position=position_dodge(.9))
ggplot(estim)+
geom_line(aes(Interval, exp(Estimate), group = Sample))+
geom_errorbar(aes(ymin = exp(Estimate - 2*SdEr), ymax = exp(Estimate + 2*SdEr), x = Interval), width=.2, position=position_dodge(.9))
conntrast <- mean(b$estim$Int4)
comtrast
conntrast <- mean(b$estim$Int4)
comtrast
contrast <- mean(b$estim$Int4)
contrast
write_csv(bio_e, paste0(OUTPUT_PATH,"/LOCR-BioEner.csv"))
# TO DO
# TO DO
# plot which would tell how much data suport each Estimate
# How to plot Bioenergetics ?
# standard error ?
ggplot(estim)+
geom_line(aes(Interval, Estimate, group = Sample))+
geom_errorbar(aes(ymin = Estimate - 2*SdEr, ymax = Estimate + 2*SdEr, x = Interval), width=.2, position=position_dodge(.9))
# try to compare the samples ...
contrast <- mean(b$estim$Int4)
ggplot(dm_r, aes(Time, LOCR))+
ggtitle("Outliar Across Samples")+
geom_vline(xintercept = c(3.5,6.5,9.5, 12.5), linetype = "dotted")+
geom_point(aes(Time, LOCR, color = out))+
facet_grid(. ~  sample_id )+
xlab("Interval Time")
read_xlsx_set_ <- function(path_, pattern_){
# returns a combined dataframe from all .xlsx files in folder (path_).
# can specify pattern to distinguish "pre" "post"  treatment as: pattern_ = "*pre/post.xlsx"
get_intervals <- function(x, y){
# Identifies Interval form measurement time  and group info Used with mapply
return(
ifelse(grepl("Background",y), "Background",
ifelse(grepl(as.character(x), "123"), "Int1",
ifelse((grepl(as.character(x), "456") & (grepl("Oligo", y)|grepl("Glyco", y))), "Int2",
ifelse((grepl(as.character(x), "456") & grepl("FCCP", y)), "Int3",
ifelse(grepl(as.character(x), "789") & grepl("Glyco", y) , "Int5",
ifelse(grepl(as.character(x), "789") & ! grepl("Glyco", y), "Int4", "Other" )))))))
}
# list of filenames
files    <- list.files(path=path_, pattern=pattern_, full.names=TRUE, recursive=FALSE)
merged_d <- data_frame()
# for every file create a data frame and merge into one
i <- 0   # to tag sample_id
list.data_frames <- lapply(files, function(x){
# Read rates
d <- read_excel(x,  sheet = "Rate")
# read assay configuration
head       <- read_excel(x,  sheet = "Assay Configuration")
assay_name <- as.character(head[3,2])
rm(head)
# # Read mmHg from raw data
# raw <- read_excel(x,  sheet = "Raw")
# raw <- raw %>% filter(Tick == "0") %>% select(c("O2 (mmHg)","Well", "Measurement") )
#
# d <- d %>% left_join(raw, by = c("Measurement", "Well"))
# rm(raw)
#
# add plateID column
d$plate_id <- rep(assay_name, times = nrow(d))
# add Protocol column
d <- d %>%
arrange(Well) %>%
mutate(Protocol = ifelse(! grepl("\\+", as.character(x)) & !Well %in% c( "A12", "H12", "D07") & 6<as.numeric(substr(Well,2,3)), NA,
ifelse(grepl("Oligo", Group), "Olig",
ifelse(grepl("FCCP",Group), "FCCP",
ifelse(grepl("Glyco", Group), "Glyco",
ifelse(grepl("Background",Group), "Background", "Other") )))))
# remove Background from OCR data
#d <- correct_background(d)
# add interval column
d$Interval <- mapply(get_intervals, d$Measurement, d$Group)
# add column with time on experiment scale
d <- d %>% mutate(Time = ifelse(Interval == "Int1" | Interval == "Int2", Measurement,
ifelse(Interval == "Int3" | Interval == "Int4", Measurement + 3, Measurement + 6)))
# the Enries with blanks should be filtered, Must be here !
d <- d %>%filter(!is.na(Protocol))
# add log OCR
d$LOCR <- sapply(d$OCR, log)
# add sample ID   If "+" in the filename recognizes two samples on plate
if (grepl("\\+", as.character(x))) {
d$sample_id <- as.character(sapply(d$Group, function(x){ substr(x,(nchar(x)+1)-7,nchar(x)) }))
}else{
d$sample_id <- rep(file_path_sans_ext(basename(x)), nrow(d))  # Takes sample name from filename
}
d <- d %>% mutate(sample_id = paste0(sample_id, "-", i))
i <<- i+1
return(d)
})
merged_d <- do.call(rbind, list.data_frames)
return(merged_d)
}
dm <- read_xlsx_set_(INPUT_PATH, ".xlsx")
background <- dm %>%
filter(Protocol == "Background") %>%
group_by(Measurement, plate_id) %>%
mutate(Z_mod = 0.6745*(OCR - median(OCR)/mad(OCR))) %>%
filter(Z_mod < 3.5) %>%
mutate(Mean_to_substr = mean(OCR)) # take mean to substract
View(background)
background <- dm %>%
filter(Protocol == "Background") %>%
group_by(Measurement, plate_id) %>%
mutate(Z_mod = 0.6745*(OCR - median(OCR)/mad(OCR))) %>%
filter(Z_mod > 3.5) %>%
mutate(Mean_to_substr = mean(OCR)) # take mean to substract
View(background)
background <- dm %>%
filter(Protocol == "Background") %>%
group_by(Measurement, plate_id) %>%
mutate(Z_mod = 0.6745*(OCR - median(OCR)/mad(OCR))) %>%
filter(Z_mod < 3.5) %>%
mutate(Mean_to_substr = mean(OCR)) # take mean to substract
View(background)
background <- dm %>%
filter(Protocol == "Background") %>%
group_by(Measurement, plate_id) %>%
mutate(Z_mod = 0.6745*(OCR - median(OCR)/mad(OCR))) %>%
filter(abs(Z_mod) < 3.5) %>%
mutate(Mean_to_substr = mean(OCR)) # take mean to substract
View(background)
?/
??outliars
??outliers
background <- dm %>%
filter(Protocol == "Background") %>%
group_by(Measurement, plate_id) %>%
mutate(Z_mod = 0.6745*abs((OCR - median(OCR))/mad(OCR))) %>%
filter(Z_mod < 3.5) %>%
mutate(Mean_to_substr = mean(OCR)) # take mean to substract
View(background)
background <- dm %>%
filter(Protocol == "Background") %>%
group_by(Measurement, plate_id) %>%
mutate(Z_mod = 0.6745*abs((OCR - median(OCR))/mad(OCR))) %>%
#filter(Z_mod < 3.5) %>%
mutate(Mean_to_substr = mean(OCR)) # take mean to substract
View(background)
background <- dm %>%
filter(Protocol == "Background") %>%
group_by(Measurement, plate_id) %>%
mutate(Z_mod = abs(0.6745*(OCR - median(OCR)/mad(OCR)))) %>%
#filter(Z_mod < 3.5) %>%
mutate(Mean_to_substr = mean(OCR)) # take mean to substract
background <- dm %>%
filter(Protocol == "Background") %>%
group_by(Measurement, plate_id) %>%
mutate( Z_mod = abs(0.6745*(OCR - median(OCR))/mad(OCR)) ) %>%
#filter(Z_mod < 3.5) %>%
mutate(Mean_to_substr = mean(OCR)) # take mean to substract
View(background)
out <- background %>% filter(Z_mod < 3.5)
out        <- background %>% filter(Z_mod > 3.5)
background <- background %>% filter(Z_mod < 3.5)
correct_background <- function(d){
# correct for outliars in background measurements and remove background
# takes wells marked as Backfround and for each plate and time substracts median of those from OCR measurements
background <- dm %>%
filter(Protocol == "Background") %>%
group_by(Measurement, plate_id) %>%
mutate( Z_mod = abs(0.6745*(OCR - median(OCR))/mad(OCR)) ) %>%
mutate(Mean_to_substr = mean(OCR)) # take mean to substract
out        <- background %>% filter(Z_mod > 3.5)
background <- background %>% filter(Z_mod < 3.5)
background <- background[!duplicated(background[,"Mean_to_substr"]),] # reduce the data before joining them
d <- d %>%
left_join(background, by = c("Measurement", "plate_id" ), suffix  = c("",".y") ) %>%
mutate(OCR = OCR - Mean_to_substr ) %>%
select(-c(contains("y"),"Z_mod", "Mean_to_substr")) %>%
filter(Protocol != "Background" )
# Print and write removed outliars
cat("There were " , nrow(out), "background measurements removed", "/n" , "Check the output file /Data/OUTPUT/RemovedBackground.csv ")
write_csv(dm_r, paste0(OUTPUT_PATH,"/RemovedBackground.csv "))
return(d)
rm(background,d)
}
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
# SET INPUT AND OUTPUT PATH
# Using function here() wil provide path to the OCR_Pipeline(package) folder on your computer,
# the input and output separate folers are in "/OCR_Pipeline/Data".
# Recomend to move the result to different folder before every analysis.
#
# To choose different folder in your coputer as I/O folder write entire Path to the folder.
INPUT_PATH  <- here('/Data/INPUT')
OUTPUT_PATH <- here('/Data/OUTPUT')
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
# SET INPUT AND OUTPUT PATH
# Using function here() wil provide path to the OCR_Pipeline(package) folder on your computer,
# the input and output separate folers are in "/OCR_Pipeline/Data".
# Recomend to move the result to different folder before every analysis.
#
# To choose different folder in your coputer as I/O folder write entire Path to the folder.
INPUT_PATH  <- here('/Data/INPUT')
OUTPUT_PATH <- here('/Data/OUTPUT')
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
# SET INPUT AND OUTPUT PATH
# Using function here() wil provide path to the OCR_Pipeline(package) folder on your computer,
# the input and output separate folers are in "/OCR_Pipeline/Data".
# Recomend to move the result to different folder before every analysis.
#
# To choose different folder in your coputer as I/O folder write entire Path to the folder.
INPUT_PATH  <- here('/Data/INPUT')
OUTPUT_PATH <- here('/Data/OUTPUT')
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
# SET INPUT AND OUTPUT PATH
# Using function here() wil provide path to the OCR_Pipeline(package) folder on your computer,
# the input and output separate folers are in "/OCR_Pipeline/Data".
# Recomend to move the result to different folder before every analysis.
#
# To choose different folder in your coputer as I/O folder write entire Path to the folder.
INPUT_PATH  <- here('/Data/INPUT')
OUTPUT_PATH <- here('/Data/OUTPUT')
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
