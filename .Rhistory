log.Basal.Glyco       = Int1 - Int5,
log.Max.Glyco.Cpcty   = Int2 - Int5,
log.Glyco.Rsrv.Cpcty  = Int2 - Int1,
log.Non.Glyco.Acid.   = Int5) %>%
select(c("Sample", "log.Basal.Glyco", "log.Max.Glyco.Cpcty", "log.Glyco.Rsrv.Cpcty", "log.Non.Glyco.Acid."))
# standard errors of mean differences
sd_n   <- cbind(sd = deviations, n = numbers)
st_errors <- sd_n %>%
mutate(Sample                = sd.sample_id,
log.Basal.Glyco       = sqrt(((sd.Int1^2)/n.Int1)+((sd.Int5^2)/n.Int5)),
log.Max.Glyco.Cpcty   = sqrt(((sd.Int2^2)/n.Int2)+((sd.Int5^2)/n.Int5)),
log.Glyco.Rsrv.Cpcty  = sqrt(((sd.Int2^2)/n.Int2)+((sd.Int1^2)/n.Int1)),
log.Non.Glyco.Acid.   = sd.Int5/sqrt(n.Int5)) %>%
select(c("Sample", "log.Basal.Glyco", "log.Max.Glyco.Cpcty", "log.Glyco.Rsrv.Cpcty", "log.Non.Glyco.Acid."))
}
return(list(bioenergetics = bio_e, standard.errors = st_errors, estimates = estim_mean ))
}
# -------------------------------------------------------------------------- COMPUTE BIOENERGETICS
compute_bioenergetics_ <- function(dm_r, method) {
dr <- dm_r %>%
filter(is.out.p == FALSE)
dr$x <- dr[[method]]
estim_mean <- dr %>%
group_by(sample_id, Interval) %>%
summarise(mean = median(x), SD = sd(x), SE = sd(x)/sqrt(n()), size = n(), CV = (SD/mean)*100 )
# form datafames
estimates  <- cast(estim_mean, sample_id~Interval, value = "mean")
deviations <- cast(estim_mean, sample_id~Interval, value = "SD")
SErrs      <- cast(estim_mean, sample_id~Interval, value = "SE")
numbers    <- cast(estim_mean, sample_id~Interval, value = "size")
CVs        <- cast(estim_mean, sample_id~Interval, value = "CV")
# compute Bioenergetics according to the method used
if (method == "OCR") {
# difference based bioenergetics
bio_e <- estimates %>%
mutate(Sample           = sample_id,
Basal.Resp       = Int1 - Int4,
ATP.linked.Resp  = Int1 - Int2,
Proton.Leak      = Int2 - Int4,
Spare.Resp.Cpcty = Int3 - Int1,
Maximal.Resp     = Int3 - Int4,
Non.Mito.Resp    = Int4) %>%
select(-c("Int1", "Int2", "Int3", "Int4", "sample_id"))
# standard errors of mean differences
sd_n   <- cbind(sd = deviations, n = numbers)
st_errors <- sd_n %>%
mutate(Sample           = sd.sample_id,
Basal.Resp       = sqrt(((sd.Int1^2)/n.Int1)+((sd.Int4^2)/n.Int4)),
ATP.linked.Resp  = sqrt(((sd.Int1^2)/n.Int1)+((sd.Int2^2)/n.Int2)),
Proton.Leak      = sqrt(((sd.Int2^2)/n.Int2)+((sd.Int4^2)/n.Int4)),
Spare.Resp.Cpcty = sqrt(((sd.Int3^2)/n.Int3)+((sd.Int1^2)/n.Int1)),
Maximal.Resp     = sqrt(((sd.Int3^2)/n.Int3)+((sd.Int4^2)/n.Int4)),
Non.Mito.Resp    = sd.Int4/sqrt(n.Int4)) %>%
select(c("Sample", "Basal.Resp", "ATP.linked.Resp", "Proton.Leak", "Spare.Resp.Cpcty", "Maximal.Resp", "Non.Mito.Resp"))
} else if (method == "LOCR") {
# Ratio based bioenergetics
bio_e <- estimates %>%
mutate(Sample               = sample_id,
log.Basal.Resp       = Int1 - Int4,
log.ATP.linked.Resp  = Int1 - Int2,
log.Proton.Leak      = Int2 - Int4,
log.Spare.Resp.Cpcty = Int3 - Int1,
log.Maximal.Resp     = Int3 - Int4,
log.Non.Mito.Resp    = Int4) %>%
select(-c("Int1", "Int2", "Int3", "Int4", "sample_id"))
# standard errors of mean differences
sd_n   <- cbind(sd = deviations, n = numbers)
st_errors <- sd_n %>%
mutate(Sample               = sd.sample_id,
log.Basal.Resp       = sqrt(((sd.Int1^2)/n.Int1)+((sd.Int4^2)/n.Int4)),
log.ATP.linked.Resp  = sqrt(((sd.Int1^2)/n.Int1)+((sd.Int2^2)/n.Int2)),
log.Proton.Leak      = sqrt(((sd.Int2^2)/n.Int2)+((sd.Int4^2)/n.Int4)),
log.Spare.Resp.Cpcty = sqrt(((sd.Int3^2)/n.Int3)+((sd.Int1^2)/n.Int1)),
log.Maximal.Resp     = sqrt(((sd.Int3^2)/n.Int3)+((sd.Int4^2)/n.Int4)),
log.Non.Mito.Resp    = sd.Int4/sqrt(n.Int4)) %>%
select(c("Sample", "log.Basal.Resp", "log.ATP.linked.Resp", "log.Proton.Leak", "log.Spare.Resp.Cpcty",
"log.Maximal.Resp", "log.Non.Mito.Resp"))
} else if (method == "ECAR") {
bio_e <- estimates %>%
mutate(Sample            = sample_id,
Basal.Glyco       = Int1 - Int5,
Max.Glyco.Cpcty   = Int2 - Int5,
Glyco.Rsrv.Cpcty  = Int2 - Int1,
Non.Glyco.Acid.   = Int5) %>%
select(c("Sample", "Basal.Glyco", "Max.Glyco.Cpcty", "Glyco.Rsrv.Cpcty", "Non.Glyco.Acid."))
# standard errors of mean differences
sd_n   <- cbind(sd = deviations, n = numbers)
st_errors <- sd_n %>%
mutate(Sample            = sd.sample_id,
Basal.Glyco       = sqrt(((sd.Int1^2)/n.Int1)+((sd.Int5^2)/n.Int5)),
Max.Glyco.Cpcty   = sqrt(((sd.Int2^2)/n.Int2)+((sd.Int5^2)/n.Int5)),
Glyco.Rsrv.Cpcty  = sqrt(((sd.Int2^2)/n.Int2)+((sd.Int1^2)/n.Int1)),
Non.Glyco.Acid.   = sd.Int5/sqrt(n.Int5)) %>%
select(c("Sample", "Basal.Glyco", "Max.Glyco.Cpcty", "Glyco.Rsrv.Cpcty", "Non.Glyco.Acid."))
} else if (method == "LECAR") {
bio_e <- estimates %>%
mutate(Sample            = sample_id,
log.Basal.Glyco       = Int1 - Int5,
log.Max.Glyco.Cpcty   = Int2 - Int5,
log.Glyco.Rsrv.Cpcty  = Int2 - Int1,
log.Non.Glyco.Acid.   = Int5) %>%
select(c("Sample", "log.Basal.Glyco", "log.Max.Glyco.Cpcty", "log.Glyco.Rsrv.Cpcty", "log.Non.Glyco.Acid."))
# standard errors of mean differences
sd_n   <- cbind(sd = deviations, n = numbers)
st_errors <- sd_n %>%
mutate(Sample                = sd.sample_id,
log.Basal.Glyco       = sqrt(((sd.Int1^2)/n.Int1)+((sd.Int5^2)/n.Int5)),
log.Max.Glyco.Cpcty   = sqrt(((sd.Int2^2)/n.Int2)+((sd.Int5^2)/n.Int5)),
log.Glyco.Rsrv.Cpcty  = sqrt(((sd.Int2^2)/n.Int2)+((sd.Int1^2)/n.Int1)),
log.Non.Glyco.Acid.   = sd.Int5/sqrt(n.Int5)) %>%
select(c("Sample", "log.Basal.Glyco", "log.Max.Glyco.Cpcty", "log.Glyco.Rsrv.Cpcty", "log.Non.Glyco.Acid."))
}
return(list(bioenergetics = bio_e, standard.errors = st_errors, estimates = estim_mean ))
}
norm.be <- compute_bioenergetics_(dr_ocr, "OCR")
log.be  <- compute_bioenergetics_(dr_ocr, "LOCR")
#write_csv(norm.be$estimates, paste0(OUTPUT_PATH,"/OCR-Estimates.csv"))
#write_csv(log.be$estimates, paste0(OUTPUT_PATH,"/LOCR-Estimates.csv"))
# Print interval estimates
norm.be$estimates %>%
kable(digits = 3) %>%
kable_styling(full_width = F)
# show estimates and error
# TO DO: add Numbers, ask if they are interested in Separate graph for each sample
ggplot(norm.be$estimates)+
ggtitle("Estimates of Intervals across samples (95% confidence)")+
geom_line(aes(Interval, mean, group = sample_id),size = 0.2, color = "Grey")+
geom_errorbar(aes(ymin = mean - 2*SE, ymax = mean + 2*SE, x = Interval), width=.2, position=position_dodge(.9))+
geom_text(aes(Interval, mean, label = paste(format(mean, digits=1, nsmall=1))),size = 3, vjust = -1)#+
#facet_wrap(.~ sample_id)+
theme_bw()
# norm estimates
ggplot(norm.be$estimates)+
ggtitle("Comparison of OCR Estimates natural scale")+
geom_boxplot(aes(Interval,mean), show.legend = FALSE)+
geom_line(aes(group = sample_id, Interval,mean), col = "grey", size = .1, show.legend = FALSE)+
geom_point(aes(Interval,mean, col = sample_id), show.legend = FALSE)+
xlab("Intervals")+
ylab("OCR")+
theme_bw()
# log estimates
ggplot(log.be$estimates)+
ggtitle("Comparison of logOCR Estimates")+
geom_boxplot(aes(Interval,mean))+
geom_line(aes(group = sample_id, Interval,mean), col = "grey", size = .1, show.legend = FALSE)+
geom_point(aes(Interval,mean, col = sample_id), show.legend = FALSE)+
xlab("Intervals")+
ylab("logOCR")+
theme_bw()
# TO DO: Ask about outlier identification here, same approach could be applied.
# log estimates
ggplot(log.be$estimates)+
ggtitle("Comparison of logOCR Estimates")+
geom_boxplot(aes(Interval,mean))+
geom_line(aes(group = sample_id, Interval,mean), col = "grey", size = .1, show.legend = FALSE)+
geom_jitter(aes(Interval,mean), show.legend = FALSE)+
xlab("Intervals")+
ylab("logOCR")+
theme_bw()
# norm estimates
ggplot(norm.be$estimates)+
ggtitle("Comparison of OCR Estimates natural scale")+
geom_boxplot(aes(Interval,mean), show.legend = FALSE)+
#geom_line(aes(group = sample_id, Interval,mean), col = "grey", size = .1, show.legend = FALSE)+
geom_jitter(aes(Interval,mean), show.legend = FALSE)+
xlab("Intervals")+
ylab("OCR")+
theme_bw()
# log estimates
ggplot(log.be$estimates)+
ggtitle("Comparison of logOCR Estimates")+
geom_boxplot(aes(Interval,mean))+
#geom_line(aes(group = sample_id, Interval,mean), col = "grey", size = .1, show.legend = FALSE)+
geom_jitter(aes(Interval,mean), show.legend = FALSE)+
xlab("Intervals")+
ylab("logOCR")+
theme_bw()
# TO DO: Ask about outlier identification here, same approach could be applied.
# ADD coefficients of variation
# normal scale Bioenergetics
n.bio <- melt(norm.be$bioenergetics)
n.bio <- filter(n.bio, variable != "Other")
ggplot(n.bio)+
ggtitle("Natural scale Bio-Energetics OCR")+
geom_boxplot(aes(variable, value))+
geom_jitter(aes(variable, value, col = Sample), show.legend = FALSE)+
xlab("Bio-Energetics")+
ylab(" ")+
theme_bw()
# add standard errors
st.err <- melt(norm.be$standard.errors, value.name = "SE", variable.name = "Bio.e" )
be.er  <- left_join(n.bio, st.err, by = c("Sample", "variable"))
be.er  <- arrange(be.er, Sample)
write_csv(n.bio, paste0(OUTPUT_PATH,"/OCR-BioEner.csv"))
# log scale Bioenergetics
l.bio   <- melt(log.be$bioenergetics )
l.bio <- filter(l.bio, variable != "Other")
ggplot(l.bio)+
ggtitle("Log scale Bio-Energetics OCR (folds)")+
geom_boxplot(aes(variable, value))+
geom_jitter(aes(variable, value, col = Sample), show.legend = FALSE)+
xlab("Bio-Energetics")+
ylab(" ")+
theme_bw()
# add standard errors
st.err <- melt(log.be$standard.errors, value.name = "SE", variable.name = "variable" )
be.er  <- left_join(l.bio, st.err, by = c("Sample", "variable"))
be.er <- arrange(be.er, Sample)
write_csv(l.bio, paste0(OUTPUT_PATH,"/LogOCR-BioEner.csv"))
# ADD coefficients of variation
# normal scale Bioenergetics
n.bio <- melt(norm.be$bioenergetics)
n.bio <- filter(n.bio, variable != "Other")
ggplot(n.bio)+
ggtitle("Natural scale Bio-Energetics OCR")+
geom_boxplot(aes(variable, value))+
geom_jitter(aes(variable, value), show.legend = FALSE)+
xlab("Bio-Energetics")+
ylab(" ")+
theme_bw()
# add standard errors
st.err <- melt(norm.be$standard.errors, value.name = "SE", variable.name = "Bio.e" )
be.er  <- left_join(n.bio, st.err, by = c("Sample", "variable"))
be.er  <- arrange(be.er, Sample)
write_csv(n.bio, paste0(OUTPUT_PATH,"/OCR-BioEner.csv"))
# log scale Bioenergetics
l.bio   <- melt(log.be$bioenergetics )
l.bio <- filter(l.bio, variable != "Other")
ggplot(l.bio)+
ggtitle("Log scale Bio-Energetics OCR (folds)")+
geom_boxplot(aes(variable, value))+
geom_jitter(aes(variable, value), show.legend = FALSE)+
xlab("Bio-Energetics")+
ylab(" ")+
theme_bw()
# add standard errors
st.err <- melt(log.be$standard.errors, value.name = "SE", variable.name = "variable" )
be.er  <- left_join(l.bio, st.err, by = c("Sample", "variable"))
be.er <- arrange(be.er, Sample)
write_csv(l.bio, paste0(OUTPUT_PATH,"/LogOCR-BioEner.csv"))
basal_maximum.OCR <- n.bio %>%
filter(variable %in% c("Basal.Resp", "Maximal.Resp")) %>%
mutate(Group = ifelse(grepl("B", Sample), "B", "A"))
filtered_basal_maximum.OCR <- filter(basal_maximum.OCR, ! Sample %in% c("11 18-09-2017 16:12", "19 25-09-2018 15:40", "2 17-10-2017 15:23", "22Bb 28-05-2018 14:34", "27Bb 18-06-2018 14:50", "32Ab 15-05-2018 14:36", "X 23-10-2017 14:54", "Y 28-11-2017 15:25") )
ggplot(filtered_basal_maximum.OCR)+
ggtitle("Normal scale Bio-Energetics OCR ")+
geom_boxplot(aes(Group, value))+
geom_jitter(aes(Group, value, col = Sample), show.legend = T)+
xlab("Bio-Energetics")+
ylab("OCR")+
facet_grid(. ~ variable ) +
theme_bw()
write_csv(basal_maximum.OCR, paste0(OUTPUT_PATH,"/OCR bio enrg.csv"))
basal_maximum.OCR <- n.bio %>%
filter(variable %in% c("Basal.Resp", "Maximal.Resp")) %>%
mutate(Group = ifelse(grepl("B", Sample), "B", "A"))
ggplot(filtered_basal_maximum.OCR)+
ggtitle("Normal scale Bio-Energetics OCR ")+
geom_boxplot(aes(Group, value))+
geom_jitter(aes(Group, value, col = Sample), show.legend = F)+
xlab("Bio-Energetics")+
ylab("OCR")+
facet_grid(. ~ variable ) +
theme_bw()
# perep for OCR interval 5 not used
d_ECAR <- dm %>% filter(!Interval %in% c("Int4","Int3") & Measurement != 7 )# & Protocol == "Glyco")
# filter out samples with any of intervals having less than 8 measurements
sumar <- d_ECAR %>%
group_by(sample_id, Interval) %>%
summarise(n = n()) %>%
filter(n < 8)
# number of intervals has to be 4 or discarted
inter <- d_ECAR %>%
group_by(sample_id) %>%
summarise(n_inter = length(unique(Interval))) %>%
filter(n_inter != 3)
d_ECAR <- d_ECAR %>%
filter(! sample_id %in% unique(sumar$sample_id)) %>%
filter(! sample_id %in% unique(inter$sample_id))
paste0("Samples removed due lack of usable measurements(less than 8  in any interval)")
unique(sumar$sample_id)
unique(inter$sample_id)
basal.OCR   <- n.bio %>% filter(variable == "Maximal.Resp")
basal.ECAR <- n.bio.ECAR %>% filter(variable == "Max.Glyco.Cpcty")
source('~/R-Projects/OCR_Pipeline/R/src/analysis_source_functions.R')
INPUT_PATH  <- here('/Data/INPUT/New_format/Matej/Data for pipeline/All/')
OUTPUT_PATH <- here('/Data/OUTPUT')
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(reshape)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
INPUT_PATH  <- here('/Data/INPUT/New_format/Matej/Data for pipeline/All/')
OUTPUT_PATH <- here('/Data/OUTPUT')
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
source('~/R-Projects/OCR_Pipeline/R/src/analysis_source_functions.R')
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(reshape)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
INPUT_PATH  <- here('/Data/INPUT/New_format/Matej/Data for pipeline/All/')
OUTPUT_PATH <- here('/Data/OUTPUT')
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
sam <- dm %>%
group_by(sample_id) %>%
summarise(N = n())
sam <- dm$rates %>%
group_by(sample_id) %>%
summarise(N = n())
View(sam)
dm <- dm$rates
sam <- dm %>%
group_by(sample_id) %>%
summarise(N = n())
View(sam)
source('~/R-Projects/OCR_Pipeline/R/src/analysis_source_functions.R')
View(sam)
substr(cicinajekrasna , 1,9)
substr("cicinajekrasna" , 1,9)
source('~/R-Projects/OCR_Pipeline/R/src/analysis_source_functions.R')
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
dm <- dm$rates
hg_out <- dm$Hg_list
View(dm)
sam <- dm %>%
group_by(sample_id) %>%
summarise(N = n())
View(sam)
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(reshape)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
INPUT_PATH  <- here('/Data/INPUT/New_format/Matej/Data for pipeline/All/')
OUTPUT_PATH <- here('/Data/OUTPUT')
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(reshape)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
INPUT_PATH  <- here('/Data/INPUT/New_format/Matej/Data for pipeline/All/')
OUTPUT_PATH <- here('/Data/OUTPUT')
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
hg_out <- dm$Hg_list
dm <- dm$rates
# perep for OCR interval 5 not used
d_OCR  <- dm %>% filter(Interval != "Int5")
# filter out samples with any of intervals having less than 8 measurements
sumar <- d_OCR %>%
group_by(sample_id, Interval) %>%
summarise(n = n()) %>%
filter(n < 20) # les then 20 so it corespods to at least 7 different wells
# number of intervals has to be 4 or discarted
inter <- d_OCR %>%
group_by(sample_id) %>%
summarise(n_inter = length(unique(Interval))) %>%
filter(n_inter != 4)
d_OCR <- d_OCR %>%
filter(! sample_id %in% unique(sumar$sample_id))
d_OCR <- d_OCR %>%
filter(! sample_id %in% unique(inter$sample_id))
paste0("Samples removed due lack of usable measurements(less than 8  in any interval)")
unique(sumar$sample_id)
unique(inter$sample_id)
sam <- dm %>%
group_by(sample_id) %>%
summarise(N = n())
samf <- dm %>%
group_by(sample_id) %>%
summarise(N = n())
View(sumar)
dm <- dm$rates
sam <- dm %>%
group_by(sample_id) %>%
summarise(N = n())
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
hg_out <- dm$Hg_list
dm <- dm$rates
# perep for OCR interval 5 not used
d_OCR  <- dm %>% filter(Interval != "Int5")
# filter out samples with any of intervals having less than 8 measurements
sumar <- d_OCR %>%
group_by(sample_id, Interval) %>%
summarise(n = n()) %>%
filter(n < 20) # les then 20 so it corespods to at least 7 different wells
# number of intervals has to be 4 or discarted
inter <- d_OCR %>%
group_by(sample_id) %>%
summarise(n_inter = length(unique(Interval))) %>%
filter(n_inter != 4)
d_OCR <- d_OCR %>%
filter(! sample_id %in% unique(sumar$sample_id))
d_OCR <- d_OCR %>%
filter(! sample_id %in% unique(inter$sample_id))
paste0("Samples removed due lack of usable measurements(less than 8  in any interval)")
unique(sumar$sample_id)
unique(inter$sample_id)
sam <- dm %>%
group_by(sample_id) %>%
summarise(N = n())
samf <- d_OCR %>%
group_by(sample_id) %>%
summarise(N = n())
View(sam)
View(samf)
source('~/R-Projects/OCR_Pipeline/R/src/analysis_source_functions.R')
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(reshape)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
INPUT_PATH  <- here('Data/INPUT/New_format/Matej/Data for pipeline/All')
OUTPUT_PATH <- here('/Data/OUTPUT')
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Make Sure You have all following packages, If not uncoment and run next line:
#source(here('/R/src/config_file.R'))
#library(data.table)
library(magrittr)   # Needed for pipe operator %>%
library(tools)
library(dplyr)
library(reshape2)
library(reshape)
library(ggplot2)
library(tidyr)      # Needed for tidy data functions like separate
library(tidyverse)
library(readxl)     # Read xlsx file
library(here)       # Used to set the path to the package dir. on the mashine
library(knitr)      # Used for tables
library(kableExtra)
# source the functions used in analysis
source(here('/R/src/analysis_source_functions.R'))
INPUT_PATH  <- here('/Data/INPUT/New_format/Matej/Data for pipeline/All/')
OUTPUT_PATH <- here('/Data/OUTPUT')
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
hg_out <- dm$Hg_list
dm <- dm$rates
# Read The the separate xlsx files from folder, Specify entire path to folder.
dm <- read_xlsx_set(INPUT_PATH, ".xlsx")
sam <- dm %>%
group_by(sample_id) %>%
summarise(N = n())
View(sam)
write_csv(sam, "final-sample_ids.csv")
